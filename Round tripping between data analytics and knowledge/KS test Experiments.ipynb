{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f4737fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7312ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_data = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a896f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28221f68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# discrete data\n",
    "# test case 1\n",
    "\n",
    "list = [1,3,5,7,9]\n",
    "data_1 = []\n",
    "data_2 = []\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(random.choice(list))\n",
    "    data_2.append(random.choice(list))\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[0] = 'Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d7a9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete data with some constant added\n",
    "# test case 2\n",
    "\n",
    "list = [1,3,5,7,9]\n",
    "data_1 = []\n",
    "data_2 = []\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(random.choice(list))\n",
    "    data_2.append(random.choice(list)+0.5)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[1] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a3adacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous data of two different normal distribution\n",
    "# test case 3\n",
    "\n",
    "from scipy.stats import norm\n",
    "data_1 = norm.rvs(0,1,size = no_of_data)\n",
    "data_2 = norm.rvs(2,0.33,size = no_of_data)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[2] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 3.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "899126a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contionuous data of two different distributions\n",
    "# test case 4\n",
    "\n",
    "from scipy.stats import chi2\n",
    "data_1 = norm.rvs(20,3,size = no_of_data)\n",
    "data_2 = chi2.rvs(19,size = no_of_data)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[3] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2705bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference of two discrete discrete distributions\n",
    "# test case 5\n",
    "\n",
    "def diff(list1,list2):\n",
    "    list3 = [i-j for i,j in zip(list1,list2)]\n",
    "    return list3\n",
    "from scipy.stats import binom,poisson\n",
    "data_1 = diff(binom.rvs(20,0.1,size = no_of_data),poisson.rvs(0.6,size = no_of_data))\n",
    "data_2 = diff(binom.rvs(20,0.1,size = no_of_data),poisson.rvs(0.6,size = no_of_data))\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[4] = 'Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 5.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ecaf7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between two continuous distributions\n",
    "# test case 6\n",
    "\n",
    "def diff(list1,list2):\n",
    "    list3 = [i-j for i,j in zip(list1,list2)]\n",
    "    return list3\n",
    "from scipy.stats import beta,anglit\n",
    "data_1 = diff(beta.rvs(2.5,0.5,size = no_of_data),anglit.rvs(0.6,size = no_of_data))\n",
    "data_2 = diff(beta.rvs(2.5,0.5,size = no_of_data),anglit.rvs(0.6,size = no_of_data))\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[5] = 'Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 6.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9a95259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two different distribution with same mean and standard deviation\n",
    "# test case 7\n",
    "\n",
    "from scipy.stats import gamma\n",
    "data_1 = norm.rvs(1,1,size=no_of_data)\n",
    "data_2 = gamma.rvs(1,size=no_of_data)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[6] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 7.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0205d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two same dist with small mean variation (1% of std deviation)\n",
    "# test case 8\n",
    "\n",
    "data_1 = norm.rvs(0,1,size=no_of_data)\n",
    "data_2 = norm.rvs(0.01,1,size=no_of_data)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[7] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 8.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "74c4eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # two same dist with large mean variation (10% of std deviation)\n",
    "# test case 9\n",
    "\n",
    "data_1 = norm.rvs(0,1,size=no_of_data)\n",
    "data_2 = norm.rvs(0.1,1,size=no_of_data)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[8] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 9.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61d92cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of distribution\n",
    "# test case 10\n",
    "\n",
    "from scipy.stats import cosine\n",
    "list1 = norm.rvs(1,1,size = no_of_data)\n",
    "list2 = cosine.rvs(size = no_of_data)\n",
    "list3 = norm.rvs(1,1,size = no_of_data)\n",
    "list4 = cosine.rvs(size = no_of_data)\n",
    "for i in range(no_of_data):\n",
    "    data_1 = [i*j for i,j in zip(list1,list2)]\n",
    "    data_2 = [i*j for i,j in zip(list3,list4)]\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[9] = 'Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 10.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d2127e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case 11\n",
    "pi=math.pi\n",
    "data_1=[]\n",
    "data_2=[]\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(math.sin(random.uniform(0,2*pi)))\n",
    "    data_2.append(math.cos(random.uniform(0,2*pi)))\n",
    "pearsonr(data_1,data_2)\n",
    "data_dict = {'Data 1':data_1,'Data 2':data_2}\n",
    "output_dict[10] = 'Not Same'\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('E:\\\\test suite ks\\\\test case 11.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7cc10cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.5967197678587084, pvalue=0.11048632395026456)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\integrate\\quadpack.py:879: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  quad_r = quad(f, low, high, args=args, full_output=self.full_output,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\integrate\\quadpack.py:879: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  quad_r = quad(f, low, high, args=args, full_output=self.full_output,\n"
     ]
    }
   ],
   "source": [
    "ttest_ind(data_1,data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8a4bbe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case 1 passed\n",
      "test case 10 passed\n",
      "test case 11 failed\n",
      "test case 2 passed\n",
      "test case 3 passed\n",
      "test case 4 passed\n",
      "test case 5 passed\n",
      "test case 6 passed\n",
      "test case 7 passed\n",
      "test case 8 failed\n",
      "test case 9 passed\n"
     ]
    }
   ],
   "source": [
    "# test suite\n",
    "\n",
    "import os\n",
    "directory = 'E:\\\\test suite ks'\n",
    "ran = [0,9,10,1,2,3,4,5,6,7,8]\n",
    "for i,files in zip(ran,os.listdir(directory)):\n",
    "    file = os.path.join(directory,files)\n",
    "    df = pd.read_csv(file)\n",
    "    data1 = df.iloc[:,0]\n",
    "    data2 = df.iloc[:,1]\n",
    "    kstat,pvalue = ks_2samp(data1,data2)\n",
    "    label = 'Same'\n",
    "    if pvalue<0.05:\n",
    "        label = 'Not Same'\n",
    "    if output_dict[i]==label:\n",
    "        print(os.path.splitext(files)[0]+' passed')\n",
    "    else:\n",
    "        print(os.path.splitext(files)[0]+' failed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "77e64ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8626053741663772, 1.2691492615270086e-297)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation tests\n",
    "from scipy.stats import pearsonr\n",
    "data_1=[]\n",
    "data_2=[]\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(random.uniform(0,1))\n",
    "    if data_1[i]>0.5:\n",
    "        data_2.append(0)\n",
    "    else:\n",
    "        data_2.append(1)\n",
    "pearsonr(data_1,data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c734b062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8641396271291537, 7.04018486861971e-300)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "data_1=[]\n",
    "data_2=[]\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(random.uniform(0,1))\n",
    "    if data_1[i]>0.5:\n",
    "        data_2.append(1)\n",
    "    else:\n",
    "        data_2.append(0)\n",
    "pearsonr(data_1,data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "59e1d161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9775450746469503, 0.0)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1=[]\n",
    "data_2=[]\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(random.uniform(0,pi/2))\n",
    "    data_2.append(math.sin(data_1[i]))\n",
    "pearsonr(data_1,data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fa26080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05867372253513073, 0.06363859369871991)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theta vs sin(theta)\n",
    "data_1=[]\n",
    "data_2=[]\n",
    "for i in range(no_of_data):\n",
    "    data_1.append(random.uniform(0,pi))\n",
    "    data_2.append(math.sin(data_1[i]))\n",
    "pearsonr(data_1,data_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
